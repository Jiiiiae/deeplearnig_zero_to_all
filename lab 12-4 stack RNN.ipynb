{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439cfde9",
   "metadata": {},
   "source": [
    "# lab 12-4 stack RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b9b8e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64e1c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\"if you want to build a ship, don't drum up people together to\"\n",
    "           \"collect wood and don't assign them tasks and work, but rather\"\n",
    "           \"teach them to long for the endless immensity of the sea.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7809fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = list(set(sentence))\n",
    "char_dic = {c:i for i,c in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eddd053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = len(char_set)\n",
    "hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "sequence_lenth = 10\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2840daf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 if you wan -> f you want\n",
      "1 f you want ->  you want \n",
      "2  you want  -> you want t\n",
      "3 you want t -> ou want to\n",
      "4 ou want to -> u want to \n",
      "5 u want to  ->  want to b\n",
      "6  want to b -> want to bu\n",
      "7 want to bu -> ant to bui\n",
      "8 ant to bui -> nt to buil\n",
      "9 nt to buil -> t to build\n",
      "10 t to build ->  to build \n",
      "11  to build  -> to build a\n",
      "12 to build a -> o build a \n",
      "13 o build a  ->  build a s\n",
      "14  build a s -> build a sh\n",
      "15 build a sh -> uild a shi\n",
      "16 uild a shi -> ild a ship\n",
      "17 ild a ship -> ld a ship,\n",
      "18 ld a ship, -> d a ship, \n",
      "19 d a ship,  ->  a ship, d\n",
      "20  a ship, d -> a ship, do\n",
      "21 a ship, do ->  ship, don\n",
      "22  ship, don -> ship, don'\n",
      "23 ship, don' -> hip, don't\n",
      "24 hip, don't -> ip, don't \n",
      "25 ip, don't  -> p, don't d\n",
      "26 p, don't d -> , don't dr\n",
      "27 , don't dr ->  don't dru\n",
      "28  don't dru -> don't drum\n",
      "29 don't drum -> on't drum \n",
      "30 on't drum  -> n't drum u\n",
      "31 n't drum u -> 't drum up\n",
      "32 't drum up -> t drum up \n",
      "33 t drum up  ->  drum up p\n",
      "34  drum up p -> drum up pe\n",
      "35 drum up pe -> rum up peo\n",
      "36 rum up peo -> um up peop\n",
      "37 um up peop -> m up peopl\n",
      "38 m up peopl ->  up people\n",
      "39  up people -> up people \n",
      "40 up people  -> p people t\n",
      "41 p people t ->  people to\n",
      "42  people to -> people tog\n",
      "43 people tog -> eople toge\n",
      "44 eople toge -> ople toget\n",
      "45 ople toget -> ple togeth\n",
      "46 ple togeth -> le togethe\n",
      "47 le togethe -> e together\n",
      "48 e together ->  together \n",
      "49  together  -> together t\n",
      "50 together t -> ogether to\n",
      "51 ogether to -> gether toc\n",
      "52 gether toc -> ether toco\n",
      "53 ether toco -> ther tocol\n",
      "54 ther tocol -> her tocoll\n",
      "55 her tocoll -> er tocolle\n",
      "56 er tocolle -> r tocollec\n",
      "57 r tocollec ->  tocollect\n",
      "58  tocollect -> tocollect \n",
      "59 tocollect  -> ocollect w\n",
      "60 ocollect w -> collect wo\n",
      "61 collect wo -> ollect woo\n",
      "62 ollect woo -> llect wood\n",
      "63 llect wood -> lect wood \n",
      "64 lect wood  -> ect wood a\n",
      "65 ect wood a -> ct wood an\n",
      "66 ct wood an -> t wood and\n",
      "67 t wood and ->  wood and \n",
      "68  wood and  -> wood and d\n",
      "69 wood and d -> ood and do\n",
      "70 ood and do -> od and don\n",
      "71 od and don -> d and don'\n",
      "72 d and don' ->  and don't\n",
      "73  and don't -> and don't \n",
      "74 and don't  -> nd don't a\n",
      "75 nd don't a -> d don't as\n",
      "76 d don't as ->  don't ass\n",
      "77  don't ass -> don't assi\n",
      "78 don't assi -> on't assig\n",
      "79 on't assig -> n't assign\n",
      "80 n't assign -> 't assign \n",
      "81 't assign  -> t assign t\n",
      "82 t assign t ->  assign th\n",
      "83  assign th -> assign the\n",
      "84 assign the -> ssign them\n",
      "85 ssign them -> sign them \n",
      "86 sign them  -> ign them t\n",
      "87 ign them t -> gn them ta\n",
      "88 gn them ta -> n them tas\n",
      "89 n them tas ->  them task\n",
      "90  them task -> them tasks\n",
      "91 them tasks -> hem tasks \n",
      "92 hem tasks  -> em tasks a\n",
      "93 em tasks a -> m tasks an\n",
      "94 m tasks an ->  tasks and\n",
      "95  tasks and -> tasks and \n",
      "96 tasks and  -> asks and w\n",
      "97 asks and w -> sks and wo\n",
      "98 sks and wo -> ks and wor\n",
      "99 ks and wor -> s and work\n",
      "100 s and work ->  and work,\n",
      "101  and work, -> and work, \n",
      "102 and work,  -> nd work, b\n",
      "103 nd work, b -> d work, bu\n",
      "104 d work, bu ->  work, but\n",
      "105  work, but -> work, but \n",
      "106 work, but  -> ork, but r\n",
      "107 ork, but r -> rk, but ra\n",
      "108 rk, but ra -> k, but rat\n",
      "109 k, but rat -> , but rath\n",
      "110 , but rath ->  but rathe\n",
      "111  but rathe -> but rather\n",
      "112 but rather -> ut rathert\n",
      "113 ut rathert -> t ratherte\n",
      "114 t ratherte ->  rathertea\n",
      "115  rathertea -> ratherteac\n",
      "116 ratherteac -> atherteach\n",
      "117 atherteach -> therteach \n",
      "118 therteach  -> herteach t\n",
      "119 herteach t -> erteach th\n",
      "120 erteach th -> rteach the\n",
      "121 rteach the -> teach them\n",
      "122 teach them -> each them \n",
      "123 each them  -> ach them t\n",
      "124 ach them t -> ch them to\n",
      "125 ch them to -> h them to \n",
      "126 h them to  ->  them to l\n",
      "127  them to l -> them to lo\n",
      "128 them to lo -> hem to lon\n",
      "129 hem to lon -> em to long\n",
      "130 em to long -> m to long \n",
      "131 m to long  ->  to long f\n",
      "132  to long f -> to long fo\n",
      "133 to long fo -> o long for\n",
      "134 o long for ->  long for \n",
      "135  long for  -> long for t\n",
      "136 long for t -> ong for th\n",
      "137 ong for th -> ng for the\n",
      "138 ng for the -> g for the \n",
      "139 g for the  ->  for the e\n",
      "140  for the e -> for the en\n",
      "141 for the en -> or the end\n",
      "142 or the end -> r the endl\n",
      "143 r the endl ->  the endle\n",
      "144  the endle -> the endles\n",
      "145 the endles -> he endless\n",
      "146 he endless -> e endless \n",
      "147 e endless  ->  endless i\n",
      "148  endless i -> endless im\n",
      "149 endless im -> ndless imm\n",
      "150 ndless imm -> dless imme\n",
      "151 dless imme -> less immen\n",
      "152 less immen -> ess immens\n",
      "153 ess immens -> ss immensi\n",
      "154 ss immensi -> s immensit\n",
      "155 s immensit ->  immensity\n",
      "156  immensity -> immensity \n",
      "157 immensity  -> mmensity o\n",
      "158 mmensity o -> mensity of\n",
      "159 mensity of -> ensity of \n",
      "160 ensity of  -> nsity of t\n",
      "161 nsity of t -> sity of th\n",
      "162 sity of th -> ity of the\n",
      "163 ity of the -> ty of the \n",
      "164 ty of the  -> y of the s\n",
      "165 y of the s ->  of the se\n",
      "166  of the se -> of the sea\n",
      "167 of the sea -> f the sea.\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0,len(sentence)-sequence_lenth):\n",
    "    x_str = sentence[i:i+sequence_lenth]\n",
    "    y_str = sentence[i+1:i+sequence_lenth+1]\n",
    "    print(i, x_str, '->', y_str)\n",
    "    \n",
    "    x = [char_dic[c] for c in x_str]\n",
    "    y = [char_dic[c] for c in y_str]\n",
    "    \n",
    "    dataX.append(x)\n",
    "    dataY.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6fdefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308e69fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 10, 25) \n",
      " (168, 10, 25)\n"
     ]
    }
   ],
   "source": [
    "x_one_hot = tf.one_hot(dataX,num_classes)\n",
    "y_one_hot = tf.one_hot(dataY,num_classes)\n",
    "print(x_one_hot.shape,'\\n',y_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1fb589d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 10, 25)            5100      \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 10, 25)            5100      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 10, 25)            650       \n",
      "=================================================================\n",
      "Total params: 10,850\n",
      "Trainable params: 10,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.0838 - accuracy: 0.1305\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.8589 - accuracy: 0.1852\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.7532 - accuracy: 0.1783\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.4354 - accuracy: 0.2466\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.0271 - accuracy: 0.3763\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5623 - accuracy: 0.5215\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2307 - accuracy: 0.6185\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.9644 - accuracy: 0.7163\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8089 - accuracy: 0.7539\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.7970\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.8368\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.8396\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.8519\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8588\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8658\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8561\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8625\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8577\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8492\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8675\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8809\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8739\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8694\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8720\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8668\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8759\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8748\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8748\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8792\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8821\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8869\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8797\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8856\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8700\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8657\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8568\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8706\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8762\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8766\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8718\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8718\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8741\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8832\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8901\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8860\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8871\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8765\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8804\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8741\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13e98e6d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(units=num_classes, input_shape = (sequence_lenth, x_one_hot.shape[2]),\n",
    "                              return_sequences = True))\n",
    "model.add(tf.keras.layers.LSTM(units = num_classes, return_sequences=True))\n",
    "model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_classes, activation = 'softmax')))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer = tf.keras.optimizers.Adam(learning_rate),\n",
    "              metrics = ['accuracy'])\n",
    "model.fit(x_one_hot,y_one_hot,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edac20c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t you want to butld a ship, don't drum up people together tocollect wood and don't dssign them tasks and work, but ratherteach them to long for the endless immensity of the sea."
     ]
    }
   ],
   "source": [
    "results = model.predict(x_one_hot)\n",
    "for j,result in enumerate(results):\n",
    "    index = np.argmax(result,axis = 1)\n",
    "    if j ==0:\n",
    "        print(''.join([char_set[t] for t in index]),end = '')\n",
    "    else:\n",
    "        print(char_set[index[-1]],end = '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf24",
   "language": "python",
   "name": "tf24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
